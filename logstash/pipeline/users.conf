# Example Logstash Pipeline for Users Index
# This pipeline syncs user data from a different MySQL instance

input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/drivers/mysql-connector-java.jar"
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://YOUR_DB_HOST_2:3306/YOUR_USER_DATABASE?serverTimezone=UTC"
    jdbc_user => "YOUR_DB_USER_2"
    jdbc_password => "YOUR_DB_PASSWORD_2"
    
    # SQL query to fetch user data
    statement => "SELECT id, username, email, first_name, last_name, created_at, updated_at FROM users WHERE updated_at > :sql_last_value ORDER BY updated_at ASC"
    
    use_column_value => true
    tracking_column => "updated_at"
    tracking_column_type => "timestamp"
    
    # Schedule: run every 5 minutes
    schedule => "*/5 * * * *"
    
    last_run_metadata_path => "/usr/share/logstash/.logstash_jdbc_last_run_users"
  }
}

filter {
  mutate {
    convert => { "id" => "string" }
    remove_field => ["@version", "@timestamp"]
  }
  
  # Combine name fields for better autocomplete
  mutate {
    add_field => {
      "[full_name]" => "%{first_name} %{last_name}"
      "[suggest]" => "%{username}"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "users"
    document_id => "%{id}"
    action => "update"
    doc_as_upsert => true
  }
  
  stdout {
    codec => rubydebug
  }
}
